{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence-Prediction report: Ben Dawson\n",
    "\n",
    "The purpose of this notebook is to report on my findings of using machine learning to predict customer movements to provide insights to aquarium/zoo owners. I have implemented and tested the following strategies:\n",
    "1) Markov Chains\n",
    "2) k-Nearest Neighbours\n",
    "3) Recurrent Neural Network\n",
    "\n",
    "Markov Chains\n",
    "Markov Chains use a transition matrix to determine the next state, given the current state. They do this by using past data to determine where the majority of past customers' next state was, and therefore assuming that is where the customer will go next. My method functions like this, however the matrix stores the amount of times customers partook in the transition as opposed to the probability of going to the next location. This provides more insight to zoo owners and reduces computation time, while still operating the same way. The matrix is stored in a json file for persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from area import Area\n",
    "from typing import List, Tuple\n",
    "import json \n",
    "\n",
    "#Makes a prediction where the user will go next given the current location\n",
    "def nextArea(current: str) -> str:\n",
    "\n",
    "    matrix = loadMarkovChain(\"matrix.json\")\n",
    "    \n",
    "    if current in matrix:\n",
    "        counts = matrix[current]\n",
    "        nextState = max(counts, key=counts.get)\n",
    "        return nextState\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#Updates the counts for the matrixes to update the probabilities\n",
    "def updateMatrix(matrix: dict, data: List[Tuple[str, str]], filename: str):\n",
    "    \n",
    "    for transition in data:\n",
    "        currentState, nextState = transition\n",
    "        if currentState in matrix and nextState in matrix[currentState]:\n",
    "            matrix[currentState][nextState] += 1\n",
    "    saveMatrix(filename, matrix)\n",
    " \n",
    "#Creates an empty transition matrix, setting all counts to 0\n",
    "def createMarkovChain(attractionAreas: List[Area], filename: str):\n",
    "\n",
    "    areas = areasToStrings(attractionAreas)\n",
    "    \n",
    "    transitionMatrix = {}\n",
    "\n",
    "    for area in areas:\n",
    "        transitionMatrix[area] = {otherArea: 0.0 for otherArea in areas if otherArea != Area}\n",
    "\n",
    "    with open (filename, 'w') as file:\n",
    "        json.dump(transitionMatrix, file, indent=4)\n",
    "\n",
    "#Loads the transition matrix from a json file so it can be used in the program\n",
    "def loadMarkovChain(filename: str) -> dict:\n",
    "    with open(filename, 'r') as file:\n",
    "        transitionMatrix = json.load(file)\n",
    "        return transitionMatrix\n",
    "    \n",
    "#Converts a list of Area objects into a list of strings, where the strings are the object names\n",
    "def areasToStrings(path: List[Area]) -> List[str]:\n",
    "    areas: List[str] = []\n",
    "    for area in path:\n",
    "        areas.append(area.get_name())\n",
    "    return areas\n",
    "\n",
    "#Generates transitions in the form (area, area) to be added to the transition matrix to update probabilities\n",
    "def generateTransitions(path: List[Area]) -> List[Tuple[str, str]]:\n",
    "\n",
    "    areas = areasToStrings(path)\n",
    "\n",
    "    transitions = []\n",
    "\n",
    "    for i in range(len(areas) - 1):\n",
    "        transitions.append((areas[i], areas[i+1]))\n",
    "    \n",
    "    return transitions\n",
    "\n",
    "#Function to save the transition matrix\n",
    "def saveMatrix(filename: str, matrix: dict):\n",
    "    with open (filename, 'w') as file:\n",
    "        json.dump(matrix, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "- Storage(size of json file) and computation time does not rise with the quantity of user data and instead with the number of attractions (this has a minimal effect)\n",
    "- Logical\n",
    "\n",
    "Cons:\n",
    "- Inefficient if the entrance and exit of the park is the same. For example, if entrance and exit is the same, while customers may go to different places from the entrance at the start of the trip, they will likely all go past the same attractions to leave the park. This may skew the transition matrix, and suggest the most likely course is for someone to immediately leave as previous movements not accounted for\n",
    "- Does not account for previous movements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "k-Nearest Neighbours is an approach that also uses past customer paths to guess where the customer will go next. The below code stores all user paths in a csv file and loads them and gives each one a score between 0 and 1 with 0 being no similarity, 1 being the exact same to the inputted path. the top 10 scores are used to work out which area the user will go to next. The scoring system has a recentcy bias, therefore the earlier paths have less weighting to where the user will go next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from area import Area\n",
    "from typing import List, Tuple\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def nearestNeighbour(filename: str, path: List[Area]) -> str:\n",
    "    \n",
    "    df = loadCSV(filename)\n",
    "\n",
    "    pathStr = convertPath(path)\n",
    "\n",
    "    addPathToCSV(filename, pathStr)\n",
    "    \n",
    "    if len(pathStr) >= len(df.columns):\n",
    "        return None\n",
    "    \n",
    "    neighbours: List[Tuple[float, str]] = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if len(pathStr) < len(row):\n",
    "            rowList = [str(item) for item in row]\n",
    "            neighbours.append(comparePaths(pathStr, rowList))\n",
    "\n",
    "    sortedNeighbours = sorted(neighbours, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    topValues = [x[0] for x in sortedNeighbours[:10]]\n",
    "\n",
    "    areaCounter = Counter()\n",
    "    for value, string in sortedNeighbours:\n",
    "        if value in topValues:\n",
    "            areaCounter[string] += 1\n",
    "    \n",
    "    mostCommonArea = areaCounter.most_common(1)\n",
    "    if mostCommonArea:\n",
    "        mostCommonArea = mostCommonArea[0][0]\n",
    "    else:\n",
    "        mostCommonArea = None\n",
    "    return mostCommonArea\n",
    "\n",
    "def loadCSV(filepath: str) -> DataFrame:\n",
    "\n",
    "    #Calculates the max amount of columns in the file i.e: the longest path\n",
    "    maxColumns = 0\n",
    "    with open (filepath, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            maxColumns = max(maxColumns, len(row))\n",
    "\n",
    "    #Apply padding to rows so effectively each row has the same length\n",
    "    with open (filepath, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            paddedRow = row + [''] * (maxColumns - len(row))\n",
    "            rows.append(paddedRow)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "#Converts the path in the form of a list of area objects into a list of strings\n",
    "def convertPath(path: List[Area]) -> List[str]:\n",
    "    areas = []\n",
    "    for area in path:\n",
    "        areas.append(area.get_name())\n",
    "    return areas\n",
    "\n",
    "#Calculates the similarity score and returns a tuple containing this score, and the next predicted area\n",
    "def comparePaths(path: List[str], row:List[str] ) -> Tuple[float, str]:\n",
    "    maxScore = (2 ** len(path)) - 1\n",
    "    score = 0\n",
    "\n",
    "    for i in range(len(path)):\n",
    "        if path[i] == row[i]:\n",
    "            score = score + (2 ** i)\n",
    "\n",
    "#Ensures that the score is a value between 0 and 1\n",
    "    normalisedScore = round(score / maxScore, 3)    \n",
    "    result = (normalisedScore, row[len(path)])\n",
    "    return result\n",
    "\n",
    "\n",
    "def addPathToCSV(filename: str, path: List[str]):\n",
    "    df = pd.DataFrame([path])\n",
    "    df.to_csv(filename, mode='a', header=False, index=False)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "- Recency bias to make it more accurate as the longer the path is, the more unique the similarity is so more likely to go to the same place\n",
    "Cons:\n",
    "- High time complexity of compuation; scales with the quantity of data\n",
    "- Memory intensive as all data must be stored permanently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks are specialised at processing and predicting sequential data. One of the ways they do this is by parameter sharing, which enables the model to work with paths with varying lengths, which would be common when tracking customer movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from area import Area\n",
    "from typing import List\n",
    "\n",
    "def loadRNN(sequences: List[List[str]], rnnUnits: int = 128, embeddingDim: int = 50):\n",
    "\n",
    "    areas = [location for seq in sequences for location in seq] #List of unique areas\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(areas) #Converts each location to an integer\n",
    "    locationIndex = tokenizer.word_index #Index for dictionary \n",
    "    numLocations = len(locationIndex)\n",
    "\n",
    "    paths = tokenizer.texts_to_sequences(sequences)\n",
    "    x = [seq[:-1] for seq in paths] #Input sequences(all but the last area on the path)\n",
    "    y = [seq[-1] for seq in paths] #Next location to predict\n",
    "\n",
    "    sequenceLength = max(len(seq) for seq in x)\n",
    "    x_padded = pad_sequences(x, maxlen=sequenceLength, padding='pre') #Pads each sequence to be the same length\n",
    "\n",
    "    x_padded = np.array(x_padded)\n",
    "    y = np.array(x)\n",
    "\n",
    "    model = Sequential([\n",
    "    Embedding(input_dim=numLocations + 1, output_dim=embeddingDim, input_length=sequenceLength),\n",
    "    LSTM(rnnUnits, return_sequences=False),\n",
    "    Dense(numLocations + 1, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_padded, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    return model\n",
    "\n",
    "def summariseModel(model):\n",
    "    model.summary()\n",
    "\n",
    "def evaluateModel(model, x, y):\n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    print(f'Test Loss: {loss}')\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "def predictNextArea(path: List[str], model, size: int) -> str:\n",
    "    pathEncoded = tokenizer.texts_to_sequences([path])\n",
    "    pathPadded = pad_sequences(pathEncoded, maxlen=path, padding='pre')\n",
    "    predictedArea = model.predict(pathPadded)\n",
    "    predictedAreaID = np.argmax(predictedArea, axis=1)[0]\n",
    "    predictedAreaName = tokenizer.index_word[predictedAreaID]\n",
    "\n",
    "    return predictedAreaName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "- Works with varying paths lengths, allowing for flexibility \n",
    "- Can capture long term dependencies \n",
    "- Very tolerant to incomplete input data\n",
    "\n",
    "Cons:\n",
    "- Requries alot of data to be trained efficiently\n",
    "- Resource intensive and long training time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION:\n",
    "- All of the methods are effective at predicting user movements\n",
    "- Markov Chains require low data to be efficient, k-nearest neighbour requires a medium amount, RNNs require a large amount\n",
    "- Markov Chains have low storage and process time, RNNs and k-NN has a larger requirement (k-Nearest-Neighbours could be re-written in java or optimised in python eg: store data as a dictionary so duplicate paths are not recorded)\n",
    "- For best results, a combination of all 3 should be used, especially if run-time isnt an issue and data is low\n",
    "- Else, the model could change its method depending on the quantity of data \n",
    "- Organic data is required to train/test the models (random data will be inefficient)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
